\documentclass[final,leqno,onefignum,onetabnum]{siamltexmm}
\usepackage{amsmath}

\title{Project proposal: Grasp-and-Lift EEG Detection\thanks{From a Kaggle competition}} 

\author{Anirudhan Jegannathan Rajagopalan, Michele Cer\'u\thanks{New York University (\email{ajr619@nyu.edu; mc3784@nyu.edu}). Questions, comments, or corrections
to this document may be directed to that email address.}}

\begin{document}
\maketitle
\newcommand{\slugmaster}{%
\slugger{siads}{xxxx}{xx}{x}{x---x}}%slugger should be set to juq, siads, sifin, or siims

\begin{abstract}
  This project aims to classify a human's hand motions from his EEG signal data.  This will help in developing Brain-Computer Interface prosthetic devices for restoring a patient's ability to perform basic daily tasks.
  We are provided with time series EEG recordings of the subjects performing the hand actions which we wish to identify.
  The baseline implemenation uses Convolutional Neural Networks for classifying the hand motion.  The baseline model has an accuracy of 0.98109 MCAUC\@.  
  We propose to use Logistic regression with Stohastic Gradient Descent for detecting the hand motions with a performance greater than or equal to the baseline.
\end{abstract}

\pagestyle{myheadings}
\thispagestyle{plain}
\markboth{Grasp-and-Lift EEG Detection}{Grasp-and-Lift EEG Detection}

\section{Introduction}
%motivation (real-world application, social good, etc.)
The main goal of this project is to identify hand motions from scalp Electroencephalogram (EEG) recordings, as described in the Kaggle competition\cite{kaggle}.
The dataset consists of 3,936 Grasp and Lift (GAL) series, meaning that the analysed subject grasped an object, held it for some seconds and then replaced it (as explained in detail in\cite{experiment}). 
Every time, without acknowledging the subject, two main properties of the object were changed: the  weight, that could be 165g, 330g or 660g, and the contact surface, that could be sandpaper, suede or silk.  In this context there are six events that represents different stages of the hand movements that we aim to predict thorough EEG analysis: 
\begin{enumerate} 
  \item \textit{HandStart}: the beginning of the movement.
  \item \textit{FirstDigitTouch}: making contact with the object.  
  \item \textit{BothStartLoadPhase}: starting to load the object. 
  \item \textit{LiftOff}: holding the object up.
  \item \textit{Replace}: replacing the object in its original position.
  \item \textit{BothReleased}: releasing the fingers from the object. 
\end{enumerate}
The training dataset contains the exact moment when this events occurred during the GAL, that were measured using the 3D position of both hand and object, electromyography signal (EMG) coming form the arm and the hand muscles of the subject, and the force/torque applied to the object. 
An important restriction to take in account while trying to predict this event, is that for a GAL we can use only data collected in past series and not use the futures one.  
This restriction is due to the fact that in a real world application there would be no access to future data.

The study aims to find a correlation between the GAL and the EEG  that could be applied on developing techniques for the control of prosthetic devices. More in general EEG lay at the base of non invasive brain computer interface BCI\cite{BCI}, that doesn't depends on neuromuscular control and therefore could be used to help patient with heavy neuromuscular disorder to interact with the environment (such as patient who have lost hand function). 

\section{Performance Criterion}
%(classification error, AUC, mean average-precision, etc.)
We will use mean column-wise Area Under the Curve (AUC) for evaluating the performance of our output.  That is the mean of individual areas under the ROC curve for each predicted columns.

\section{Problem Formulation}
The training set consists of time series information for twelve subjects performing 8 series of GAL tasks.  We are provided with a data file consisting of the EEG recordings from the 32 electrodes.  A corresponding events file describes the event corresponding to the data file.\\
The model that we build for learning the data should adher to `No future data' rule\cite{kaggledata} which means that when predicting, we should not use data from the future.  We should also take care not to include data leakage.  For example, we should not center data for a series using the data from future events in the same series.


%%%%%%%%%%%%%%%%%%%%CHANGED PART
Each signal is sampled with a 500Hz frequency. We will divide the signal in several fixed interval of times, each of this temporal window will contain a fixed number of data points $N$, that will be an hyper parameter for the program. Considering the sampling frequency of the data set, the minimum size of the windows will be $0.2 s$ (so to contain at list 100 data points). 
%We will then sample data points in this interval with a frequency $f_s$, that will be another hyper parameter of the program, so the number of sample point considered in the window will be:
%$$
%N=Tf_s
%$$
For each of this window we can then write the Discrete Fourier Transformation (DFT) as:
\begin{equation}
  \label{DFT}
  F(n) =\sum_{k=0}^{N-1}x(k)e^{\frac{2\pi i kn}{N}}
\end{equation}  
Ranging $k$ from $0$ to $N-1$ this equation represent the $N$ frequencies that describe the wave inside the window.\\
Applying the Fast Fourier Transformation (FFT) algorithm\cite{FFT} we will calculate all this frequencies for all windows in the signal. This process will be applied to each of the signals in the data set. The training data set consists of $96$ files with $32$ signals each. Approximately a file has $200,000$ data point, then the total number of data points is $96\times 32 \times 200,000$. If we take windows of $N=100$ number of samples we will have $96\times 32 \times 2,000=6,144,000$ discrete Fourier transformation, and each of them will generate a vector $x_t$. So we will have a set of $X=\{x_t,t=1\dots T\}$ sample vectors. The probability density function  $u_\lambda$  that models this samples
depends on the parameters $[\lambda_1\dots \lambda_M]$ that represent the set of feature that we what to calculate. We will use the Fisher Vector\cite{fisher} with the Stochastic Gradient Descent algorithm to find the features that maximise the log-likelihood:
\begin{equation}\label{loglikelihood}
G_\lambda^X= \nabla_\lambda \log u_\lambda(X)
\end{equation}

%%%%%%%%%%%%%%%%%%%%

%The test set consists of data files for 12 subjects performing GAL\@.
%The input can be represented by a feature vector of size 32 (m = 32).  
%Due to `No future data' rule, we should be careful to center/scale the data only till the series which is being processed at that instant.

We will use logistic regression to classify the input events.  We need to use six different classifiers with each corresponding to one of the hand events described in introduction section.  Logistic regression is given by the function
\begin{align*}
  J(\theta) = & \frac{1}{m} \sum_{i = 1}^{m} \mathrm{Cost}(h_{\theta}(x^{i}), y^{(i)}) \\
  = & -\frac{1}{m} [\sum_{i=1}^{m} y^{(i)} \log{h_{\theta}(x^{(i)} )} + (1 - y^{(i)}) \log{( 1 - h_{\theta}(x^{(i)}) )}]
\end{align*}

Where,

h is the sigmoid function of theta.

\(\theta\) is the error funcction

We then minimize \(J(\theta)\) using stochastic gradient descent to find the optimal classifier for the given input set.

\section{Algorithm}
The algorithm used in the baseline consists of two main approaches. The first one applies Logistic Regression and Linear Discriminant Analysis (LDA) on features describing the sample of the dataset. The second one uses Neural Network in a not event-specific way. Convolutional Neural Network is trained to find the correlation between all electrode at equal time (2D spatial correlation) and the correlation between a current event with a set of samples from the past events (1D temporal correlation). Recurrent Neural Network is also used to find temporal correlation.


\section{Baseline method, algorithm, software}
%(including relevant bibliographic references/urls)
We consider the scripts with most accurate results in the Kaggle competition for baseline\cite{kaggleleaderboard}.  We use the first level implementation by \textit{Cat \& Dog}\cite{kagglewinners} as our baseline.
The baseline method uses Logistic regression with LDA for providing an event specific view of the data.  There were also two level1 Neural Network approaches that were not event specific.

The model consists of using a covariance matrix for encoding the spatial information between the electrodes.  It was found that low frequency data has considerable predective information.  So a ``Filter bank'' approach was used to give more weightage to low frequency data.

\section{Short description of the dataset}
The  datasets consist of data collected with 12 subjects, each of them performing 10 series, each consisting of approximately 30 grasp and Lift performed. The Data is divided in a  training set, containing the first 8 series for each subject, and  the testing set contains the last two series.
In the dataset each of this event correspond to a binary variable (1 if the event is present and 0 otherwise), and we see that the list of event always present in the same other, but the event are not all mutually exclusive meaning that some of  them could be 1 at the same time.  

\begin{thebibliography}{1}
  \bibitem{kaggle} Kaggle competition:  https://www.kaggle.com/c/grasp-and-lift-eeg-detection
  \bibitem{experiment} http://www.nature.com/articles/sdata201447
  \bibitem{BCI}D. J. McFarland and J. R. Wolpaw. Brain-computer interfaces for communication and control. Commun. ACM, 54(5):60?66, May 2011.
  \bibitem{baseline}https://github.com/alexandrebarachant/Grasp-and-lift-EEG-challenge
  \bibitem{model}https://hal.inria.fr/hal-00830491/file/journal.pdf
  \bibitem{kagglewinners}https://github.com/alexandrebarachant/Grasp-and-lift-EEG-challenge
  \bibitem{kaggleleaderboard}https://www.kaggle.com/c/grasp-and-lift-eeg-detection/leaderboard
  \bibitem{kaggledata}https://www.kaggle.com/c/grasp-and-lift-eeg-detection/data
  \bibitem{fisher}https://hal.inria.fr/hal-00830491/file/journal.pdf
  \bibitem{FFT}Fast Fourier Transforms, Connexions online book edited by C. Sidney Burrus, with chapters by C. Sidney Burrus, Ivan Selesnick, Markus Pueschel, Matteo Frigo, and Steven G. Johnson (2008)
\end{thebibliography} 


\end{document}
%% end of file `docultexmm.tex'
