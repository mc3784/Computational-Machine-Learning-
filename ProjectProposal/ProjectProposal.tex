\documentclass[final,leqno,onefignum,onetabnum]{siamltexmm}

\title{Project proposal: Grasp-and-Lift EEG Detection\thanks{From a Kaggle competition}} 

\author{Anirudhan Jegannathan Rajagopalan, Michele Cer\'u\thanks{New York University (\email{anirudhan.jegannathan@nyu.edu; mc3784@nyu.edu}). Questions, comments, or corrections
to this document may be directed to that email address.}}

\begin{document}
\maketitle
\newcommand{\slugmaster}{%
\slugger{siads}{xxxx}{xx}{x}{x---x}}%slugger should be set to juq, siads, sifin, or siims

  \begin{abstract}
    This project aims to classify a human's hand motions from his EEG signal data.  This will help in developing Brain-Computer Interface prosthetic devices for restoring a patient's ability to perform basic daily tasks.
    We are provided with time series EEG recordings of the subjects performing the hand actions which we wish to identify.
    The current implementation which will be used as baseline uses Convolutional Neural Networks for detecting this with an accuracy of 0.98109 MCAUC\@.  
    We propose to use Logistic regression with Stohastic Gradient Descent for detecting the hand motions with a performance greater than or equal to the baseline.
  \end{abstract}

  \pagestyle{myheadings}
  \thispagestyle{plain}
  \markboth{Grasp-and-Lift EEG Detection}{Grasp-and-Lift EEG Detection}

  \section{Introduction}
  %motivation (real-world application, social good, etc.)
  The main goal of this project is to identify hand motions from scalp Electroencephalogram (EEG) recordings, as described in the Kaggle competition\cite{kaggle}.
  The dataset consists of 3,936 Grasp and Lift (GAL) series, meaning that the analysed subject grasped an object, held it for some seconds and then replaced it (as explained in detail in\cite{experiment}). 
  Every time, without acknowledging the subject, two main properties of the object were changed: the  weight, that could be 165g, 330g or 660g, and the contact surface, that could be sandpaper, suede or silk.  In this context there are six events that represents different stages of the hand movements that we aim to predict thorough EEG analysis: 
  \begin{enumerate} 
    \item \textit{HandStart}: the beginning of the movement.
    \item \textit{FirstDigitTouch}: making contact with the object.  
    \item \textit{BothStartLoadPhase}: starting to load the object. 
    \item \textit{LiftOff}: holding the object up.
    \item \textit{Replace}: replacing the object in its original position.
    \item \textit{BothReleased}: releasing the fingers from the object. 
  \end{enumerate}
  The training dataset contains the exact moment when this events occurred during the GAL, that were measured using the 3D position of both hand and object, electromyography signal (EMG) coming form the arm and the hand muscles of the subject, and the force/torque applied to the object. 
  An important restriction to take in account while trying to predict this event, is that for a GAL we can use only data collected in past series and not use the futures one.  
  This restriction is due to the fact that in a real world application there would be no access to future data.

  The study aims to find a correlation between the GAL and the EEG  that could be applied on developing techniques for the control of prosthetic devices. More in general EEG lay at the base of non invasive brain computer interface BCI\cite{BCI}, that doesn't depends on neuromuscular control and therefore could be used to help patient with heavy neuromuscular disorder to interact with the environment (such as patient who have lost hand function). 

  \section{Performance Criterion}
  %(classification error, AUC, mean average-precision, etc.)
  We will use mean column-wise Area Under the Curve (AUC) for evaluating the performance of our output.  That is the mean of individual areas under the ROC curve for each predicted columns.

  \section{Problem Formulation}

  \section{Algorithm}
  %(the one(s) used in the reference papers)

  The reference implementation uses 


\section{Baseline method, algorithm, software}
%(including relevant bibliographic references/urls)
The Kaggle competition winners\cite{kaggle} provided a solution based on three levels. The first level is dedicated to features extraction using mainly two different methods. The first one uses Covariance matrices  estimated using a sliding window (of around 500 samples). Considering the six events to predict and the absence of them we can model seven different brain states to predict. They estimated the geometric mean of the covariance matrices, producing in this way a seven dimensional feature vector. The second one is based on the fact that the signal contains predictive information in low frequency, so they used a ``Filter Bank'' approach to extract this features. Then they combine the results obtained with this two methods to generate the final set of features. 
The main algorithms used for this level are Logistic Regression, Convolutional Neural network and Recurrent Neural Network. 
 
%a feature vector of size 7. This procedure can be viewed as a supervised manifold embedding with a Riemannian metric.

\section{short description of the dataset}
The  datasets consist of data collected with 12 subjects, each of them performing 10 series, each consisting of approximately 30 grasp and Lift performed. The Data is divided in a  training set, containing the first 8 series for each subject, and  the testing set contains the last two series.
In the dataset each of this event correspond to a binary variable (1 if the event is present and 0 otherwise), and we see that the list of event always present in the same other, but the event are not all mutually exclusive meaning that some of  them could be 1 at the same time.  
 

  %\section{Performance metric} 
  %The metric we are going to use will be based on the multi class precision-recal:


  %\Appendix
  %\section{The use of appendices}
  %\appendix
  %\section{Title of appendix} Each one will be sequentially lettered

  \begin{thebibliography}{1}
    \bibitem{kaggle} Kaggle competition:  https://www.kaggle.com/c/grasp-and-lift-eeg-detection
    \bibitem{experiment} http://www.nature.com/articles/sdata201447
    \bibitem{BCI}D. J. McFarland and J. R. Wolpaw. Brain-computer interfaces for communication and control.
Commun. ACM, 54(5):60?66, May 2011.
    \bibitem{baseline}https://github.com/alexandrebarachant/Grasp-and-lift-EEG-challenge
    \bibitem{model}https://hal.inria.fr/hal-00830491/file/journal.pdf

    \bibitem{features1}http://www.laccei.org/LACCEI2010-Peru/published/EInn156\_Delgado.pdf
    \bibitem{features2}Autoregressive Estimation of Short Segment Spectra for Computerized EEG Analysis Jansen, Ben H.Bourne, John R. Ward, James W. Department of Electrical and Biomedical Engineering, School of
Engineering, School of Medicine, Vanderbilt University. 
    \bibitem{fisher}https://hal.inria.fr/hal-00830491/file/journal.pdf


  \end{thebibliography} 


  \end{document}
  %% end of file `docultexmm.tex'
